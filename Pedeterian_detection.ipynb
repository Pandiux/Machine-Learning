{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Color Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7d7336c8c426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgamma_color_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def gamma_color_normalization(img):\n",
    "    return 255*(np.sqrt(img/255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(img):\n",
    "    img_gradX = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = 1)\n",
    "    img_gradY = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = 1)\n",
    "    img_grad = (np.add(np.square(img_gradX), np.square(img_gradY)))\n",
    "    img_grad_i = np.argmax(img_grad, axis = 2)\n",
    "    i, j = np.ogrid[:img.shape[0], :img.shape[1]]\n",
    "    img_gradX = img_gradX[i, j, img_grad_i]\n",
    "    img_gradY = img_gradY[i, j, img_grad_i]\n",
    "    return img_gradX, img_gradY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. HOG Descriptor(8x8 block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hog(grad_mag, grad_angle):\n",
    "    hog_vector = np.zeros((1,9))\n",
    "    grad_angle = grad_angle%180;\n",
    "    for i in range(grad_mag.shape[0]):\n",
    "        for j in range(grad_angle.shape[1]):\n",
    "            l = int(grad_angle[i][j]//20)\n",
    "            r = (l+1)\n",
    "            hog_vector[0,l-1] = (grad_mag[i, j])*((r*20 - (grad_angle[i, j]))/20)\n",
    "            hog_vector[0,r-1] = (grad_mag[i, j])*((grad_angle[i, j] - l*20)/20)\n",
    "    return hog_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Image Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_vector(img):\n",
    "    img_new  = cv2.resize(img, (64, 128))      #width = 64, height = 128\n",
    "    img_new = img_new.astype('float64')\n",
    "    img_new = gamma_color_normalization(img_new)\n",
    "    img_gradX, img_gradY = grad(img_new);\n",
    "    grad_mag, grad_angle = cv2.cartToPolar(img_gradX, np.abs(img_gradY), angleInDegrees = True)\n",
    "    grad_angle = grad_angle.astype(np.uint8)\n",
    "    hog_vector = np.empty(shape = (1, 0))\n",
    "    for i in range(15):\n",
    "        for j in range(7):\n",
    "            temp_vector = np.empty(shape = (1, 0))\n",
    "            x1, y1 = i*8, j*8\n",
    "            x2, y2 = x1+8, y1 +8\n",
    "            temp_vector = np.concatenate((temp_vector,\n",
    "                                         hog(grad_mag[x1:x2, y1:y2],\n",
    "                                            grad_angle[x1:x2, y1:y2])), axis = 1)\n",
    "            x1+=8\n",
    "            x2 = x1+8\n",
    "            temp_vector = np.concatenate((temp_vector,\n",
    "                                         hog(grad_mag[x1:x2, y1:y2],\n",
    "                                            grad_angle[x1:x2, y1:y2])), axis = 1)\n",
    "            y1+=8\n",
    "            y2= y1+8\n",
    "            temp_vector = np.concatenate((temp_vector,\n",
    "                                         hog(grad_mag[x1:x2, y1:y2],\n",
    "                                            grad_angle[x1:x2, y1:y2])), axis = 1)\n",
    "            x1-=8\n",
    "            x2-=8\n",
    "            temp_vector = np.concatenate((temp_vector,\n",
    "                                         hog(grad_mag[x1:x2, y1:y2],\n",
    "                                            grad_angle[x1:x2, y1:y2])), axis = 1)\n",
    "            Norm = np.linalg.norm(temp_vector)\n",
    "            temp_vector/=Norm;\n",
    "            hog_vector = np.concatenate(( hog_vector, temp_vector), axis = 1)\n",
    "    return hog_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "fold = os.path.realpath('INRIAPerson/test_64x128_H96/pos/crop001001a.png')\n",
    "fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read images and calculate HOG descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amit/Downloads/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2416\n",
      "14596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.14993267,  0.24720085,  0.06180021, ...,  0.24432929,\n",
       "         0.07421722,  0.27832623]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptor = image_vector(\"/INRIAPerson/train_64x128_H96/pos/crop001001a.png\")\n",
    "# import the necessary packages\n",
    "from __future__ import print_function\n",
    "from imutils.object_detection import non_max_suppression\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import imutils\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "X = np.zeros(shape = (14596, 3780))\n",
    "y = np.empty(shape = (14596, 1))\n",
    "y[:2416] = 1;\n",
    "y[2416:] = 0;\n",
    "\n",
    "i = 0\n",
    "for filename in glob.glob(\"INRIAPerson/96X160H96/Train/pos/*.png\"):\n",
    "    img = (Image.open(filename).convert('RGB'))\n",
    "    img1 = (np.array(img.getdata())).reshape(160, 96, 3).astype(np.uint8)\n",
    "    X[i] = image_vector(img1[16:144,16:80,:])*255\n",
    "    i+=1\n",
    "print(i)\n",
    "\n",
    "for filename in glob.glob(\"INRIAPerson/Train/neg/*\"):\n",
    "    img = cv2.imread(filename)\n",
    "    patches = image.extract_patches_2d(img, (128, 64), max_patches = 10)\n",
    "    for j in range(10):\n",
    "        X[i] = image_vector(patches[j])*255\n",
    "        i+=1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14596, 3780) (14596, 1)\n"
     ]
    }
   ],
   "source": [
    "# print(X.shape, y.shape)\n",
    "temp = np.concatenate((X,y), axis = 1)\n",
    "np.random.shuffle(temp)\n",
    "X = temp[:,:-1]\n",
    "y = (temp[:,-1])\n",
    "y.shape = (-1,1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training using SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13909, 3780) (13909,)\n",
      "Score on test(Validation) data: 0.936300844206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3085</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True Label          0    1\n",
       "Predicted Label           \n",
       "0                3085  125\n",
       "1                 124  575"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "y = y[~np.isnan(X).any(axis = 1)]\n",
    "X = X[~np.isnan(X).any(axis = 1)]\n",
    "print(X.shape, y.shape)\n",
    "y = y.reshape(-1,)\n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(X[:10000,:], y[:10000])\n",
    "print(\"Score on test(Validation) data:\",clf.score(X[10000:,:], y[10000:]))\n",
    "c_matrix = confusion_matrix(y[10000:], clf.predict(X[10000:,:]))\n",
    "df = pd.DataFrame(c_matrix)\n",
    "df.columns.name = \"True Label\"\n",
    "df.index.name = \"Predicted Label\"\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((clf.coef_).shape, X.shape, clf.intercept_.shape)\n",
    "intercept = clf.intercept_.reshape(-1,1)\n",
    "print((clf.coef_).shape, X.shape, intercept.shape)\n",
    "np.savetxt(\"coef.txt\", np.hstack(( clf.coef_, intercept)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style = \"height:2px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I couldn't be able to test it as sliding window method is taking a lot of time. We need to use library CUDA and more optimized algorithm for sliding window. So I am leaving that part and we will see how it works in real life using openCv pre-trained model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## openCv Pre-Trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.object_detection import non_max_suppression\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "# initialize the HOG descriptor/person detector\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "imagePath = \"INRIAPerson/Train/pos/crop001003.png\"\n",
    "# load the image and resize it.\n",
    "image = cv2.imread(imagePath)\n",
    "image = imutils.resize(image, width=min(400, image.shape[1]))\n",
    "orig = image.copy()\n",
    "\n",
    "# detect people in the image\n",
    "(rects, weights) = hog.detectMultiScale(image, winStride=(4, 4),\n",
    "    padding=(8, 8), scale=1.05)\n",
    "\n",
    "# draw the original bounding boxes\n",
    "for (x, y, w, h) in rects:\n",
    "    cv2.rectangle(orig, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "# apply non-maxima suppression.\n",
    "rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    "\n",
    "# draw the final bounding boxes\n",
    "for (xA, yA, xB, yB) in pick:\n",
    "    cv2.rectangle(image, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "\n",
    "# show the output images\n",
    "cv2.imshow(\"IMAGE\", image)\n",
    "if cv2.waitKey(0)==27:\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
